{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "better-prior",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'main' from 'train' (D:\\Senior Year Northeastern University\\DS Capstone\\ImageOutpainting\\model\\train.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c1595bc23ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmasking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask_transforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDatum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mApplyMaskTransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomRightTransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaskedAreaTransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmasking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask_gen\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRightStripeMaskGenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTopStripeMaskGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'main' from 'train' (D:\\Senior Year Northeastern University\\DS Capstone\\ImageOutpainting\\model\\train.py)"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, 'D:\\Senior Year Northeastern University\\DS Capstone\\ImageOutpainting\\model')\n",
    "sys.argv[1] = \"pix2pix\"\n",
    "#print(sys.path)\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import torch\n",
    "from PIL import ImageColor, Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from train import main\n",
    "from masking.mask_transforms import Datum, ApplyMaskTransform, RandomRightTransform, MaskedAreaTransform\n",
    "from masking.mask_gen import RightStripeMaskGenerator, TopStripeMaskGenerator\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(self, img):\n",
    "    if not self.config.recur_bool:\n",
    "        return img\n",
    "    elif self.config.recur_direction == \"top\":\n",
    "        return img[:,\n",
    "                  self.config.stripe_width::,\n",
    "                  self.config.stripe_width:,\n",
    "                  self.config.stripe_width:]\n",
    "    elif self.config.recur_direction == \"bottom\":\n",
    "        return img[:,\n",
    "                  :self.config.pic_height-self.config.stripe_width,\n",
    "                  :self.config.pic_height-self.config.stripe_width,\n",
    "                  :self.config.pic_height-self.config.stripe_width]\n",
    "    elif self.config.recur_direction == \"left\":\n",
    "        return img[:,\n",
    "                  self.config.stripe_width:,\n",
    "                  self.config.stripe_width:,\n",
    "                  self.config.stripe_width:]\n",
    "    elif self.config.recur_direction == \"right\":\n",
    "        return img[:,\n",
    "                  :self.config.pic_width-self.config.stripe_width,\n",
    "                  :self.config.pic_width-self.config.stripe_width,\n",
    "                  :self.config.pic_width-self.config.stripe_width]\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot shift image in direction {self.config.recur_direction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    def show(self, img):\n",
    "        toPIL = transforms.ToPILImage()\n",
    "        img = toPIL(img[:, :3, :, :][0])\n",
    "        plt.imshow(img)\n",
    "u = Utils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader:\n",
    "    def __init__(self, filepaths):\n",
    "        self.filepaths = filepaths\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for fp in self.filepaths:\n",
    "            to_yield = Image.open(fp), None\n",
    "            yield to_yield\n",
    "            \n",
    "class LeftImageLoader:\n",
    "    def __init__(self, filepaths):\n",
    "        self.filepaths = filepaths\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for fp in self.filepaths:\n",
    "            to_yield = Image.open(fp), None\n",
    "            yield to_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurDataset(torch.utils.data.IterableDataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(OutsideRightDataset).__init__()\n",
    "        self.dataset = self.load_dataset()\n",
    "                \n",
    "    def __iter__(self):\n",
    "        for x, _ in iter(self.dataset):\n",
    "            both = transforms.Compose([\n",
    "                transforms.Resize((config.pic_height, config.pic_width)),\n",
    "                transforms.ToTensor(),\n",
    "                RandomRightTransform(config, right_chance = 1.1)\n",
    "            ])\n",
    "\n",
    "            xonly = ApplyMaskTransform(config, extra_dim=(not config.should_collapse))\n",
    "            yonly = MaskedAreaTransform(config)\n",
    "            p = both(x)\n",
    "            yield xonly(p), yonly(p)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.train_dataset)\n",
    "    \n",
    "    def get_pic_filepaths(self):\n",
    "        for pic in os.listdir(\"model\\dataset\\places365_standard\\train\\boardwalk\"):\n",
    "            yield os.path.join(\"model\\dataset\\places365_standard\\train\\boardwalk\", pic)\n",
    "                \n",
    "    def load_dataset(self):\n",
    "        filepaths = list(self.get_pic_filepaths())\n",
    "        return RightImageLoader(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "recur_loader = RecurDataset().dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "both = transforms.Compose([\n",
    "                transforms.Resize((config.pic_height, config.pic_width)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                RandomRightTransform(config, right_chance = -0.1)\n",
    "            ])\n",
    "xonly = ApplyMaskTransform(config, extra_dim=(not config.should_collapse))\n",
    "yonly = MaskedAreaTransform(config)\n",
    "\n",
    "for i, (X, y) in enumerate(recur_loader):\n",
    "    p = both(X)\n",
    "    x_, y_ = xonly(p), yonly(p)\n",
    "    x_, y_ = torch.reshape(x_, (1, x_.shape[0], x_.shape[1], x_.shape[2])), torch.reshape(y_, (1, y_.shape[0], y_.shape[1], y_.shape[2]))\n",
    "    x_ = x_.to(torch.device('cuda'))\n",
    "    print(x_.device)\n",
    "    break\n",
    "    \n",
    "u.show(x_)\n",
    "print(x_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.show(gen(x_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-evening",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
